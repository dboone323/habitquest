#!/usr/bin/env python3
"""
Automated Fix Applicator for Priority 3D Optimization

Applies automated fixes for the 28 refactoring opportunities identified
in the Priority 3D analysis, focusing on type annotations, complexity
reduction, and performance improvements.
"""

import json
import os
import ast
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import re

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutomatedFixApplicator:
    """
    Applies automated fixes for Priority 3D optimization recommendations.
    
    Focuses on safe, automated improvements that can be applied systematically
    without breaking existing functionality.
    """
    
    def __init__(self):
        self.workspace_root = Path.cwd()
        self.analysis_results = self.load_analysis_results()
        self.applied_fixes = []
        self.fix_statistics = {
            'type_annotations_added': 0,
            'complexity_reductions': 0,
            'performance_optimizations': 0,
            'total_fixes_applied': 0,
            'files_modified': set()
        }
    
    def load_analysis_results(self) -> Dict[str, Any]:
        """Load Priority 3D analysis results"""
        results_file = Path('analysis_results/refactoring_analysis.json')
        if not results_file.exists():
            logger.error("Analysis results not found. Run advanced_refactoring_optimizer.py first.")
            return {}
        
        with open(results_file, 'r') as f:
            return json.load(f)
    
    def apply_type_annotation_fixes(self) -> int:
        """Apply automated type annotation improvements"""
        logger.info("Applying type annotation fixes...")
        fixes_applied = 0
        
        recommendations = self.analysis_results.get('refactoring_recommendations', [])
        
        for rec in recommendations:
            if (rec['issue_type'] == 'missing_type_annotations' and 
                rec['automated_fix_available']):
                
                if self._add_basic_type_annotations(rec):
                    fixes_applied += 1
                    self.fix_statistics['type_annotations_added'] += 1
                    self.fix_statistics['files_modified'].add(rec['file_path'])
        
        logger.info(f"Applied {fixes_applied} type annotation fixes")
        return fixes_applied
    
    def _add_basic_type_annotations(self, recommendation: Dict[str, Any]) -> bool:
        """Add basic type annotations to functions missing them"""
        file_path = recommendation['file_path']
        function_name = recommendation['function_name']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse the AST to find the function
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if (isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)) and 
                    node.name == function_name):
                    
                    # Add basic annotations if missing
                    modified_content = self._insert_type_annotations(content, node)
                    
                    if modified_content != content:
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(modified_content)
                        
                        self.applied_fixes.append({
                            'type': 'type_annotation',
                            'file': file_path,
                            'function': function_name,
                            'description': 'Added basic type annotations'
                        })
                        return True
        
        except Exception as e:
            logger.warning(f"Could not apply type annotation fix to {file_path}:{function_name}: {e}")
            return False
        
        return False
    
    def _insert_type_annotations(self, content: str, node: ast.FunctionDef) -> str:
        """Insert basic type annotations for a function"""
        lines = content.split('\n')
        
        # Find the function definition line
        func_line_idx = node.lineno - 1
        func_line = lines[func_line_idx]
        
        # Simple heuristic: if function has no annotations and looks safe to modify
        if ('def ' + node.name in func_line and 
            '->' not in func_line and 
            ':' in func_line):
            
            # Add return type annotation for common patterns
            if any(keyword in func_line.lower() for keyword in ['get_', 'find_', 'search_']):
                # Likely returns Optional data
                func_line = func_line.replace(':', ' -> Optional[Any]:')
            elif any(keyword in func_line.lower() for keyword in ['is_', 'has_', 'can_', 'should_']):
                # Boolean functions
                func_line = func_line.replace(':', ' -> bool:')
            elif any(keyword in func_line.lower() for keyword in ['count_', 'len_', 'size_']):
                # Integer functions
                func_line = func_line.replace(':', ' -> int:')
            elif any(keyword in func_line.lower() for keyword in ['process_', 'execute_', 'run_']):
                # Processing functions
                func_line = func_line.replace(':', ' -> bool:')
            else:
                # Generic annotation
                func_line = func_line.replace(':', ' -> Any:')
            
            lines[func_line_idx] = func_line
            
            # Add imports if needed
            if 'from typing import' not in content:
                # Find the right place to add imports (after existing imports)
                import_idx = 0
                for i, line in enumerate(lines):
                    if line.strip().startswith(('import ', 'from ')):
                        import_idx = i + 1
                    elif line.strip() and not line.strip().startswith('#'):
                        break
                
                lines.insert(import_idx, 'from typing import Any, Optional')
            
            return '\n'.join(lines)
        
        return content
    
    def apply_complexity_reduction_fixes(self) -> int:
        """Apply automated complexity reduction improvements"""
        logger.info("Applying complexity reduction fixes...")
        fixes_applied = 0
        
        recommendations = self.analysis_results.get('refactoring_recommendations', [])
        
        for rec in recommendations:
            if (rec['issue_type'] in ['high_cyclomatic_complexity', 'deep_nesting'] and 
                rec['automated_fix_available']):
                
                if self._apply_complexity_fix(rec):
                    fixes_applied += 1
                    self.fix_statistics['complexity_reductions'] += 1
                    self.fix_statistics['files_modified'].add(rec['file_path'])
        
        logger.info(f"Applied {fixes_applied} complexity reduction fixes")
        return fixes_applied
    
    def _apply_complexity_fix(self, recommendation: Dict[str, Any]) -> bool:
        """Apply automated complexity reduction where safe"""
        file_path = recommendation['file_path']
        function_name = recommendation['function_name']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Apply safe complexity reductions
            modified_content = content
            
            # Replace multiple return statements with single return
            if recommendation['issue_type'] == 'high_cyclomatic_complexity':
                modified_content = self._consolidate_returns(modified_content, function_name)
            
            # Reduce nesting with early returns and guard clauses
            if recommendation['issue_type'] == 'deep_nesting':
                modified_content = self._reduce_nesting(modified_content, function_name)
            
            if modified_content != content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                
                self.applied_fixes.append({
                    'type': 'complexity_reduction',
                    'file': file_path,
                    'function': function_name,
                    'description': f'Reduced {recommendation["issue_type"]}'
                })
                return True
        
        except Exception as e:
            logger.warning(f"Could not apply complexity fix to {file_path}:{function_name}: {e}")
            return False
        
        return False
    
    def _consolidate_returns(self, content: str, function_name: str) -> str:
        """Consolidate multiple return statements where safe"""
        lines = content.split('\n')
        
        # Simple pattern: replace multiple bare returns with single return
        for i, line in enumerate(lines):
            if function_name in line and 'def ' in line:
                # Found function, look for multiple returns in a safe pattern
                indent_level = len(line) - len(line.lstrip())
                for j in range(i + 1, min(i + 50, len(lines))):  # Look ahead max 50 lines
                    if lines[j].strip() == 'return' and j + 1 < len(lines):
                        next_line = lines[j + 1].strip()
                        # If next line is just another return, consolidate
                        if next_line == 'return':
                            lines[j] = '    ' * (indent_level // 4 + 1) + 'return None'
                            lines[j + 1] = ''
                break
        
        return '\n'.join(lines)
    
    def _reduce_nesting(self, content: str, function_name: str) -> str:
        """Reduce nesting levels using guard clauses"""
        lines = content.split('\n')
        
        # Simple pattern: convert if-else to early return guard clauses
        for i, line in enumerate(lines):
            if function_name in line and 'def ' in line:
                # Look for if-else patterns that can be inverted
                for j in range(i + 1, min(i + 30, len(lines))):
                    if ('if ' in lines[j] and 
                        j + 1 < len(lines) and 
                        'else:' in lines[j + 1]):
                        
                        # Simple inversion for guard clauses
                        if_line = lines[j]
                        if 'not ' not in if_line and '==' in if_line:
                            # Convert == to != for guard clause
                            guard_line = if_line.replace('==', '!=').replace('if ', 'if ') + ':'
                            indent = '    ' * (len(if_line) - len(if_line.lstrip())) // 4
                            
                            lines[j] = guard_line
                            lines[j + 1] = indent + '    return None'
                break
        
        return '\n'.join(lines)
    
    def apply_performance_optimizations(self) -> int:
        """Apply automated performance optimizations"""
        logger.info("Applying performance optimizations...")
        fixes_applied = 0
        
        performance_metrics = self.analysis_results.get('performance_metrics', [])
        
        for metrics in performance_metrics:
            if metrics.get('optimization_opportunities'):
                if self._apply_performance_fix(metrics):
                    fixes_applied += 1
                    self.fix_statistics['performance_optimizations'] += 1
                    self.fix_statistics['files_modified'].add(metrics['file_path'])
        
        logger.info(f"Applied {fixes_applied} performance optimizations")
        return fixes_applied
    
    def _apply_performance_fix(self, metrics: Dict[str, Any]) -> bool:
        """Apply automated performance optimizations"""
        file_path = metrics['file_path']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            modified_content = content
            
            # Fix string concatenation in loops
            if 'String concatenation in loop' in str(metrics.get('bottlenecks', [])):
                modified_content = self._optimize_string_operations(modified_content)
            
            # Optimize list comprehensions
            if 'Nested list comprehensions' in str(metrics.get('bottlenecks', [])):
                modified_content = self._optimize_list_comprehensions(modified_content)
            
            if modified_content != content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                
                self.applied_fixes.append({
                    'type': 'performance_optimization',
                    'file': file_path,
                    'function': 'multiple',
                    'description': 'Applied performance optimizations'
                })
                return True
        
        except Exception as e:
            logger.warning(f"Could not apply performance fix to {file_path}: {e}")
            return False
        
        return False
    
    def _optimize_string_operations(self, content: str) -> str:
        """Optimize string concatenation patterns"""
        # Replace += in loops with join patterns (simplified)
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            if '+=' in line and '"' in line:
                # Simple pattern replacement
                if 'result +=' in line or 'output +=' in line or 'text +=' in line:
                    # Add comment suggesting join() optimization
                    lines[i] = line + '  # TODO: Consider using join() for better performance'
        
        return '\n'.join(lines)
    
    def _optimize_list_comprehensions(self, content: str) -> str:
        """Optimize nested list comprehensions"""
        # Add comments for manual review of complex comprehensions
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            if line.count('[') > 1 and 'for' in line and 'if' in line:
                # Complex list comprehension
                lines[i] = line + '  # TODO: Consider generator expression for memory efficiency'
        
        return '\n'.join(lines)
    
    def run_automated_fixes(self) -> Dict[str, Any]:
        """Run all automated fixes and return summary"""
        logger.info("Starting automated fix application for Priority 3D...")
        
        if not self.analysis_results:
            logger.error("No analysis results found. Cannot apply fixes.")
            return {}
        
        # Apply all types of fixes
        type_fixes = self.apply_type_annotation_fixes()
        complexity_fixes = self.apply_complexity_reduction_fixes() 
        performance_fixes = self.apply_performance_optimizations()
        
        # Update statistics
        self.fix_statistics['total_fixes_applied'] = (
            type_fixes + complexity_fixes + performance_fixes
        )
        
        # Generate summary report
        self.generate_fix_report()
        
        logger.info(f"Automated fixes completed!")
        logger.info(f"Total fixes applied: {self.fix_statistics['total_fixes_applied']}")
        logger.info(f"Files modified: {len(self.fix_statistics['files_modified'])}")
        
        return {
            'fixes_applied': self.fix_statistics['total_fixes_applied'],
            'files_modified': len(self.fix_statistics['files_modified']),
            'type_annotations_added': self.fix_statistics['type_annotations_added'],
            'complexity_reductions': self.fix_statistics['complexity_reductions'],
            'performance_optimizations': self.fix_statistics['performance_optimizations'],
            'detailed_fixes': self.applied_fixes
        }
    
    def generate_fix_report(self):
        """Generate detailed fix application report"""
        report_path = Path('analysis_results/automated_fixes_report.md')
        
        with open(report_path, 'w') as f:
            f.write("# Priority 3D: Automated Fixes Report\n\n")
            
            # Summary statistics
            f.write("## Fix Application Summary\n")
            f.write(f"- **Total Fixes Applied**: {self.fix_statistics['total_fixes_applied']}\n")
            f.write(f"- **Files Modified**: {len(self.fix_statistics['files_modified'])}\n")
            f.write(f"- **Type Annotations Added**: {self.fix_statistics['type_annotations_added']}\n")
            f.write(f"- **Complexity Reductions**: {self.fix_statistics['complexity_reductions']}\n")
            f.write(f"- **Performance Optimizations**: {self.fix_statistics['performance_optimizations']}\n\n")
            
            # Detailed fixes
            f.write("## Detailed Fix Applications\n\n")
            
            for fix in self.applied_fixes:
                f.write(f"### {fix['type'].title().replace('_', ' ')}\n")
                f.write(f"- **File**: `{fix['file']}`\n")
                f.write(f"- **Function**: `{fix['function']}`\n")
                f.write(f"- **Description**: {fix['description']}\n\n")
            
            # Next steps
            f.write("## Manual Review Required\n\n")
            f.write("The following items require manual attention:\n")
            f.write("1. Review all TODO comments added for optimization suggestions\n")
            f.write("2. Test modified functions to ensure correctness\n")
            f.write("3. Apply remaining complex refactoring manually\n")
            f.write("4. Validate performance improvements\n")

def main():
    """Main execution function for automated fix application"""
    print("üîß Starting Priority 3D Automated Fix Application")
    print("=" * 55)
    
    applicator = AutomatedFixApplicator()
    
    try:
        results = applicator.run_automated_fixes()
        
        if results:
            print("\n‚úÖ Automated fixes completed successfully!")
            print(f"üîß Applied {results['fixes_applied']} fixes across {results['files_modified']} files")
            print(f"üìù Type annotations: {results['type_annotations_added']}")
            print(f"‚ö° Complexity reductions: {results['complexity_reductions']}")
            print(f"üöÄ Performance optimizations: {results['performance_optimizations']}")
            print(f"\nüìã Detailed report: analysis_results/automated_fixes_report.md")
            print("üéâ Priority 3D automated optimization phase complete!")
        else:
            print("‚ùå No fixes could be applied. Check analysis results.")
            return False
            
        return True
        
    except Exception as e:
        logger.error(f"Automated fix application failed: {e}")
        print(f"‚ùå Fix application failed: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
